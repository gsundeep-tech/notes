{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TODO Need to find markdown editor for vs code Link the sections here Update the contents when reading the new item Scaler: https://www.scaler.com/topics/data-structures/","title":"TODO"},{"location":"#todo","text":"Need to find markdown editor for vs code Link the sections here Update the contents when reading the new item Scaler: https://www.scaler.com/topics/data-structures/","title":"TODO"},{"location":"ds_and_algo/binary_search/","text":"Binary Search Binary search is a searching algorithm when the elements follow a certain order/pattern Basic Syntax Iterative Binary Search def binary_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: ans = mid break return ans Space Complexity: O(1) Time Complexity: O(logn) Recursive Binary Search def binary_search(low, high, nums, target): if low < high: return False else: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal == target: return mid elif midVal < target: return binary_search(mid + 1, high, nums, target) else: return binary_search(low, mid - 1, nums, target) Space Complexity: O(logn) - recursive stack space Time Complexity: O(logn) Variations of Binary Search In the one dimensional array, we can observe the following patterns of binary search 1. Single Value Comparison 1. Index of a key 2. Index the left most key (or first target key) if duplicates are present 3. Index the right most Key (or last target key) if duplicates are present 4. Index of the least element greater than key 5. Index of the greatest element lesser than key 6. Nearest element to the target element 2. Two Values Comparison 1. Comparing the adjacent elements - Peaks in the given Array 2. Comparing with the end elements - Find the index where the array is rotated 3. Three Values Comparison 1. Finding the range - Find the start and end index of target Single Value Comparison 1.1 Index of a key use the basic syntax to find the key def binary_search(low, high, nums, target): ans = -1 # use the low <= high if we are calculating the mid using the way mentioned in code while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: ans = mid break return ans Space Complexity: O(1) Time Complexity: O(logn) 1.2 Index the left most key (or first target key) if duplicates are present As we want to search for the left most key or the first key, we need to decrease the right value so that out window is closer to the left side of the nums def binary_left_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # As we need to search for the left value, high has to be decreased ans = mid high = mid - 1 return ans Space Complexity: O(1) Time Complexity: O(logn) 1.3 Index the right most key (or last target key) if duplicates are present As we want to search for the right most key or the last key, we need to increase the left value so that out window is closer to the right side of the nums def binary_right_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # As we need to search for the right value, left has to be increased ans = mid left = mid + 1 return ans Space Complexity: O(1) Time Complexity: O(logn) 1.4 Index of the least element greater than key def binary_greater_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: # here, the current mid value is a possible answer so we update the ans to mid ans = mid high = mid - 1 elif midVal == target: # we cannot write ans = mid + 1 here because what if the value we are searching for is the last element and there is no greater element than that last element, So instead we update the window to the right side low = mid + 1 return ans Space Complexity: O(1) Time Complexity: O(logn) 1.5 Index of the greatest element lesser than key def binary_lesser_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: # here, the current mid value is a possible answer so we update the ans to mid ans = mid low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # we cannot write ans = mid - 1 here because what if the value we are searching for is the first element and there is no lesser element than that first element, So instead we update the window to the left side high = mid - 1 return ans Space Complexity: O(1) Time Complexity: O(logn) 1.6 Nearest element to the target def binary_nearest_search(low, high, nums, target): \"\"\" perform the regular binary search \"\"\" while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal == target: return midVal elif midVal > target: high = mid - 1 elif midVal < target: low = mid + 1 \"\"\" if the target is present in the nums, we'll return the target but if the target is not present in the nums, following code would be executed, left and right would be already pointing to the two closest elements to target. We need to find which is the closest out of those two. Here we are doing some post processing as well after the binary search. \"\"\" if abs(target - nums[left]) < abs(target - nums[right]): return nums[left] return nums[right] Space Complexity: O(1) Time Complexity: O(logn) 2.1 Get any peak in the array def binary_peak_search(low, high, nums, target): # As we are supposed to compare the current mid with the beside element, then we need to use < rather than <= # Note: <= is used for one value comparison and < can be used for two values comparison (mid and mid-1) while low < high: mid = low + (high - low + 1) // 2 if nums[mid-1] < nums[mid]: # this can be the peak, so we are not incrementing by 1 low = mid else: # As we know that mid - 1 value is higher so we are in the lower end so we need to shift our right high = mid - 1 return left Space Complexity: O(1) Time Complexity: O(logn) 2.2 Find the index where array is rotated def binary_rotated_idx_search(low, high, nums, target): \"\"\" Example 1: Consider a rotated Array [4, 5, 6, 7, 0, 1, 2, 3] - here the rotation happened at index 3 (i.e., element 7) Example 2: [0, 1, 2, 3, 4, 5] - here the order is not changed, so we need to check for the condition if the first element is less than the last elemenet Here we are comparing the mid with the left element reason why we are not searching with the previous element is there might be a scenario mid will be at second half of divided array Example: [6, 0, 1, 2, 3, 4, 5] - in this example mid will be at 3rd index at fist pass and if we are following the previous example it will return 5 (value) but the actual answer is 6 (value) \"\"\" while low <= high: mid = low + (high - low + 1) // 2 if nums[low] < nums[mid]: # this means we didn't find the peak yet so we are moving towards the right window low = mid + 1 else: # this can be a peak but we are not sure, so we are keeping the mid as the high high = mid return left Space Complexity: O(1) Time Complexity: O(logn) 3.1 Finding the range of the target This is similar to finding the right most target and left most target that we have discussed in the 1.2 & 1.3 sections TODO Search for more articles and add more content References https://www.geeksforgeeks.org/binary-search/ https://www.geeksforgeeks.org/variants-of-binary-search/ Related Problems https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/ https://leetcode.com/problems/find-peak-element/ - two values comparison problem https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/ - find the rotated index https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/ - Find the range","title":"Binary Search"},{"location":"ds_and_algo/binary_search/#binary-search","text":"Binary search is a searching algorithm when the elements follow a certain order/pattern","title":"Binary Search"},{"location":"ds_and_algo/binary_search/#basic-syntax","text":"Iterative Binary Search def binary_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: ans = mid break return ans Space Complexity: O(1) Time Complexity: O(logn) Recursive Binary Search def binary_search(low, high, nums, target): if low < high: return False else: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal == target: return mid elif midVal < target: return binary_search(mid + 1, high, nums, target) else: return binary_search(low, mid - 1, nums, target) Space Complexity: O(logn) - recursive stack space Time Complexity: O(logn)","title":"Basic Syntax"},{"location":"ds_and_algo/binary_search/#variations-of-binary-search","text":"In the one dimensional array, we can observe the following patterns of binary search 1. Single Value Comparison 1. Index of a key 2. Index the left most key (or first target key) if duplicates are present 3. Index the right most Key (or last target key) if duplicates are present 4. Index of the least element greater than key 5. Index of the greatest element lesser than key 6. Nearest element to the target element 2. Two Values Comparison 1. Comparing the adjacent elements - Peaks in the given Array 2. Comparing with the end elements - Find the index where the array is rotated 3. Three Values Comparison 1. Finding the range - Find the start and end index of target","title":"Variations of Binary Search"},{"location":"ds_and_algo/binary_search/#single-value-comparison","text":"","title":"Single Value Comparison"},{"location":"ds_and_algo/binary_search/#11-index-of-a-key","text":"use the basic syntax to find the key def binary_search(low, high, nums, target): ans = -1 # use the low <= high if we are calculating the mid using the way mentioned in code while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: ans = mid break return ans Space Complexity: O(1) Time Complexity: O(logn)","title":"1.1 Index of a key"},{"location":"ds_and_algo/binary_search/#12-index-the-left-most-key-or-first-target-key-if-duplicates-are-present","text":"As we want to search for the left most key or the first key, we need to decrease the right value so that out window is closer to the left side of the nums def binary_left_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # As we need to search for the left value, high has to be decreased ans = mid high = mid - 1 return ans Space Complexity: O(1) Time Complexity: O(logn)","title":"1.2 Index the left most key (or first target key) if duplicates are present"},{"location":"ds_and_algo/binary_search/#13-index-the-right-most-key-or-last-target-key-if-duplicates-are-present","text":"As we want to search for the right most key or the last key, we need to increase the left value so that out window is closer to the right side of the nums def binary_right_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # As we need to search for the right value, left has to be increased ans = mid left = mid + 1 return ans Space Complexity: O(1) Time Complexity: O(logn)","title":"1.3 Index the right most key (or last target key) if duplicates are present"},{"location":"ds_and_algo/binary_search/#14-index-of-the-least-element-greater-than-key","text":"def binary_greater_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: low = mid + 1 elif midVal > target: # here, the current mid value is a possible answer so we update the ans to mid ans = mid high = mid - 1 elif midVal == target: # we cannot write ans = mid + 1 here because what if the value we are searching for is the last element and there is no greater element than that last element, So instead we update the window to the right side low = mid + 1 return ans Space Complexity: O(1) Time Complexity: O(logn)","title":"1.4 Index of the least element greater than key"},{"location":"ds_and_algo/binary_search/#15-index-of-the-greatest-element-lesser-than-key","text":"def binary_lesser_search(low, high, nums, target): ans = -1 while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal < target: # here, the current mid value is a possible answer so we update the ans to mid ans = mid low = mid + 1 elif midVal > target: high = mid - 1 elif midVal == target: # we cannot write ans = mid - 1 here because what if the value we are searching for is the first element and there is no lesser element than that first element, So instead we update the window to the left side high = mid - 1 return ans Space Complexity: O(1) Time Complexity: O(logn)","title":"1.5 Index of the greatest element lesser than key"},{"location":"ds_and_algo/binary_search/#16-nearest-element-to-the-target","text":"def binary_nearest_search(low, high, nums, target): \"\"\" perform the regular binary search \"\"\" while low <= high: mid = low + (high - low + 1) // 2 midVal = nums[mid] if midVal == target: return midVal elif midVal > target: high = mid - 1 elif midVal < target: low = mid + 1 \"\"\" if the target is present in the nums, we'll return the target but if the target is not present in the nums, following code would be executed, left and right would be already pointing to the two closest elements to target. We need to find which is the closest out of those two. Here we are doing some post processing as well after the binary search. \"\"\" if abs(target - nums[left]) < abs(target - nums[right]): return nums[left] return nums[right] Space Complexity: O(1) Time Complexity: O(logn)","title":"1.6 Nearest element to the target"},{"location":"ds_and_algo/binary_search/#21-get-any-peak-in-the-array","text":"def binary_peak_search(low, high, nums, target): # As we are supposed to compare the current mid with the beside element, then we need to use < rather than <= # Note: <= is used for one value comparison and < can be used for two values comparison (mid and mid-1) while low < high: mid = low + (high - low + 1) // 2 if nums[mid-1] < nums[mid]: # this can be the peak, so we are not incrementing by 1 low = mid else: # As we know that mid - 1 value is higher so we are in the lower end so we need to shift our right high = mid - 1 return left Space Complexity: O(1) Time Complexity: O(logn)","title":"2.1 Get any peak in the array"},{"location":"ds_and_algo/binary_search/#22-find-the-index-where-array-is-rotated","text":"def binary_rotated_idx_search(low, high, nums, target): \"\"\" Example 1: Consider a rotated Array [4, 5, 6, 7, 0, 1, 2, 3] - here the rotation happened at index 3 (i.e., element 7) Example 2: [0, 1, 2, 3, 4, 5] - here the order is not changed, so we need to check for the condition if the first element is less than the last elemenet Here we are comparing the mid with the left element reason why we are not searching with the previous element is there might be a scenario mid will be at second half of divided array Example: [6, 0, 1, 2, 3, 4, 5] - in this example mid will be at 3rd index at fist pass and if we are following the previous example it will return 5 (value) but the actual answer is 6 (value) \"\"\" while low <= high: mid = low + (high - low + 1) // 2 if nums[low] < nums[mid]: # this means we didn't find the peak yet so we are moving towards the right window low = mid + 1 else: # this can be a peak but we are not sure, so we are keeping the mid as the high high = mid return left Space Complexity: O(1) Time Complexity: O(logn)","title":"2.2 Find the index where array is rotated"},{"location":"ds_and_algo/binary_search/#31-finding-the-range-of-the-target","text":"This is similar to finding the right most target and left most target that we have discussed in the 1.2 & 1.3 sections","title":"3.1 Finding the range of the target"},{"location":"ds_and_algo/binary_search/#todo","text":"Search for more articles and add more content","title":"TODO"},{"location":"ds_and_algo/binary_search/#references","text":"https://www.geeksforgeeks.org/binary-search/ https://www.geeksforgeeks.org/variants-of-binary-search/","title":"References"},{"location":"ds_and_algo/binary_search/#related-problems","text":"https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/ https://leetcode.com/problems/find-peak-element/ - two values comparison problem https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/ - find the rotated index https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/ - Find the range","title":"Related Problems"},{"location":"ds_and_algo/dp/","text":"Dynamic Programming Patterns 0/1 Knapsack Unbounded Knapsack Shortest Path (eg: Unique Paths I/II) Fibonacci Sequence (eg: House Thief, Jump Game) Longest Common Substring/Subsequeunce https://leetcode.com/discuss/general-discussion/712010/The-ART-of-Dynamic-Programming-An-Intuitive-Approach%3A-from-Apprentice-to-Master","title":"Dp"},{"location":"ds_and_algo/graph/","text":"Union Find class UnionFind: def __init__(self, size): self.root = [i for i in range(size)] def find(self, x): if x == self.root[x]: return x self.root[x] = self.find(self.root[x]) return self.root[x] def union(self, x, y): parentX = self.find(x) parentY = self.find(y) if parentX < parentY: self.root[parentY] = parentX else: self.root[parentX] = parentY def connected(self, x, y): return self.find(x) == self.find(y) Using Ranking - more optimized way class UnionFind: def __init__(self, size): self.root = [i for i in range(size)] self.rank = [1] * size def find(self, x): if self.root[x] == x: return x self.root[x] = self.find(self.root[x]) return self.root[x] def union(self, x, y): parentX = self.find(x) parentY = self.find(y) if parentX != parentY: if self.rank[parentX] > self.rank[parentY]: self.root[parentY] = parentX elif self.rank[parentY] > self.rank[parentX]: self.root[parentX] = parentY else: self.root[parentY] = parentX self.rank[parentX] += 1 def is_connected(self, x, y): return self.find(x) == self.find(y) Minimum Spanning Tree 1. Krushkal's Algo 2. Prim's Algo Krushkal's Algorithm krushkal's Algorithm is based on the union find. we sort all the edges based on the weight and add to the union find if the edges doesn't form a cycle. Cycle can be indentified if two nodes has the same parent. Once we have added all the edges we'll get the requirement minimum spanning tree class UnionFind: def __init__(self, size): self.parent = [i for i in range(size)] self.rank = [1] * size def find(self, x): while x != self.parent[x]: x = self.parent[x] return x def union(self, x, y): parentX = self.find(x) parentY = self.find(y) # cycle detected if parentX == parentY: return False if self.rank[parentX] < self.rank[parentY]: self.parent[parentX] = parentY elif self.rank[parentY] < self.rank[parentX]: self.parent[parentY] = parentX else: self.parent[parentY] = parentX self.rank[parentX] += 1 return True def minimum_spanning_tree(num_of_nodes, edges): \"\"\" num_of_nodes: total num of nodes edges: a tuple in the format of (src, dest, wt) \"\"\" edges = sorted(edges, key=lambda x: x[2]) uf = UnionFind(size=num_of_nodes) spanning_tree_edges = [] for (src, dest, wt) in edges: if uf.union(src, dest): spanning_tree_edges((src, dest, wt)) return spanning_tree_edges Traversal 1. BFS 2. DFS def bfs(graph, source=(0, 0), destination=(0, 0)): \"\"\" Graph dict[list]: Graph is passed as a adjacency list \"\"\" Shortest Path 1. Dijkstra's Algo 2. A Star 3. Bidirectional BFS 1. Dijkstra's Algo Dijkstra's Algorithm is used to find the shortest distance from a given source in a weighted graph without negative edges Note: It works only on the weighted graph without negative edges, for negative edges we need to use the Bellman Ford Algorithm Problem: Given a graph and a source vertex in the graph, find the shortest paths from the source to all vertices in the given graph def single_source_shortest_path_for_adjacency_list(graph, source): \"\"\" graph: Adjacency list with the (node, weight) source: source node Reference: 1. https://www.tutorialspoint.com/Dijkstra-s-Algorithm-for-Adjacency-List-Representation 2. https://www.scaler.com/topics/data-structures/dijkstra-algorithm/ \"\"\" num_nodes = len(graph) distance = {} distance[source] = 0 visited = {} prev = [None] * num_nodes heap = [(0, source)] while len(heap) > 0: dist, curr_node = heapq.heappop(heap) if curr_node in visited: continue visited[curr_node] = True for adj_node, weight in graph.get(curr_node): if adj_node in visited: continue if dist + weight < distance.get(adj_node, float('inf')): distance[adj_node] = dist + weight heapq.heapappend(heap, (adj_node, dist + weight)) prev[adj_node] = curr_node print(distance) # shortest distance from the source to all nodes print(prev) # path to achieve that shortest distance def single_source_shortest_path_for_adjacency_matrix(graph, source): \"\"\" graph: Matrix with weights as the values and indexes would be the nodes source: source node \"\"\" rows_length = len(graph) cols_length = len(graph[0]) distance = {} visited = {} distance[(source[0], source[1])] = 0 heap = [(0, source[0], source[1])] dirs = [(0, 1), (0, -1), (1, 0), (-1, 0)] while len(heap) > 0: dist, curr_x, curr_y = heapq.heappop(heap) if (curr_x, curr_y) in visited: continue visited[(curr_x, curr_y)] = True for (_x, _y) in dirs: new_x = curr_x + _x new_y = curr_y + _y if (new_x, new_y) in visited: continue if 0 <= new_x < rows_length and 0 <= new_y < cols_length and dist + graph[new_x][new_y] < distance.get((new_x, new_y), float('inf')): distance[(new_x, new_y)] = dist + graph[new_x][new_y] heapq.heapappend(heap, (dist + graph[new_x][new_y], new_x, new_y)) print(distance) All Pairs Shortest Path 1. Bellman Ford's Algo","title":"Graph"},{"location":"ds_and_algo/graph/#1-dijkstras-algo","text":"Dijkstra's Algorithm is used to find the shortest distance from a given source in a weighted graph without negative edges Note: It works only on the weighted graph without negative edges, for negative edges we need to use the Bellman Ford Algorithm Problem: Given a graph and a source vertex in the graph, find the shortest paths from the source to all vertices in the given graph def single_source_shortest_path_for_adjacency_list(graph, source): \"\"\" graph: Adjacency list with the (node, weight) source: source node Reference: 1. https://www.tutorialspoint.com/Dijkstra-s-Algorithm-for-Adjacency-List-Representation 2. https://www.scaler.com/topics/data-structures/dijkstra-algorithm/ \"\"\" num_nodes = len(graph) distance = {} distance[source] = 0 visited = {} prev = [None] * num_nodes heap = [(0, source)] while len(heap) > 0: dist, curr_node = heapq.heappop(heap) if curr_node in visited: continue visited[curr_node] = True for adj_node, weight in graph.get(curr_node): if adj_node in visited: continue if dist + weight < distance.get(adj_node, float('inf')): distance[adj_node] = dist + weight heapq.heapappend(heap, (adj_node, dist + weight)) prev[adj_node] = curr_node print(distance) # shortest distance from the source to all nodes print(prev) # path to achieve that shortest distance def single_source_shortest_path_for_adjacency_matrix(graph, source): \"\"\" graph: Matrix with weights as the values and indexes would be the nodes source: source node \"\"\" rows_length = len(graph) cols_length = len(graph[0]) distance = {} visited = {} distance[(source[0], source[1])] = 0 heap = [(0, source[0], source[1])] dirs = [(0, 1), (0, -1), (1, 0), (-1, 0)] while len(heap) > 0: dist, curr_x, curr_y = heapq.heappop(heap) if (curr_x, curr_y) in visited: continue visited[(curr_x, curr_y)] = True for (_x, _y) in dirs: new_x = curr_x + _x new_y = curr_y + _y if (new_x, new_y) in visited: continue if 0 <= new_x < rows_length and 0 <= new_y < cols_length and dist + graph[new_x][new_y] < distance.get((new_x, new_y), float('inf')): distance[(new_x, new_y)] = dist + graph[new_x][new_y] heapq.heapappend(heap, (dist + graph[new_x][new_y], new_x, new_y)) print(distance) All Pairs Shortest Path 1. Bellman Ford's Algo","title":"1. Dijkstra's Algo"},{"location":"ds_and_algo/linked_lists/","text":"TODO Cycle Detection - Floyd","title":"TODO"},{"location":"ds_and_algo/linked_lists/#todo","text":"Cycle Detection - Floyd","title":"TODO"},{"location":"ds_and_algo/maths/","text":"TODO seive of eratosthenes - prime factorial","title":"TODO"},{"location":"ds_and_algo/maths/#todo","text":"seive of eratosthenes - prime factorial","title":"TODO"},{"location":"ds_and_algo/prefix_sum/","text":"","title":"Prefix Sum"},{"location":"ds_and_algo/sorting/","text":"Merge Sort Heap Sort Quick Sort Quick Select Tim Sort 4. Quick Select Quick select is used to sort the first k elements. Any problem to return the kth highest or smallest element we can use the quick select def partition(numbers, left, right, idx): numbers[idx], numbers[right] = numbers[right], numbers[idx] swap_idx = left for i in range(left, right): # swap all the lesser elements towards the left side if numbers[i] < numbers[right]: numbers[i], numbers[swap_idx] = numbers[swap_idx], numbers[i] swap_idx += 1 numbers[swap_idx], numbers[right] = numbers[right], numbers[swap_idx] return swap_idx def quickselect(numbers, left, right, k): if left == right: return numbers[left] # any random index can be selected, here we are considering the mid element idx = (left + right) // 2 idx = partition(numbers, left, right, idx) if idx == k: return numbers[idx] if idx > k: return quickselect(numbers, left, idx - 1, k) else: return quickselect(numbers, idx + 1, right, k) # numbers are sorted from smallest to the largest # if we want the second smallest then we can give k-1 as the argument value # if we want the second largest then we can give len(numbers) - k as the argument value quickselect(numbers, 0, len(numbers)-1, k-1) Note: Median of Medians is also a selection algorithm we can use as an alternative for quickselect, but from the interviews perspective quickselect would be a good option","title":"Sorting"},{"location":"ds_and_algo/sorting/#4-quick-select","text":"Quick select is used to sort the first k elements. Any problem to return the kth highest or smallest element we can use the quick select def partition(numbers, left, right, idx): numbers[idx], numbers[right] = numbers[right], numbers[idx] swap_idx = left for i in range(left, right): # swap all the lesser elements towards the left side if numbers[i] < numbers[right]: numbers[i], numbers[swap_idx] = numbers[swap_idx], numbers[i] swap_idx += 1 numbers[swap_idx], numbers[right] = numbers[right], numbers[swap_idx] return swap_idx def quickselect(numbers, left, right, k): if left == right: return numbers[left] # any random index can be selected, here we are considering the mid element idx = (left + right) // 2 idx = partition(numbers, left, right, idx) if idx == k: return numbers[idx] if idx > k: return quickselect(numbers, left, idx - 1, k) else: return quickselect(numbers, idx + 1, right, k) # numbers are sorted from smallest to the largest # if we want the second smallest then we can give k-1 as the argument value # if we want the second largest then we can give len(numbers) - k as the argument value quickselect(numbers, 0, len(numbers)-1, k-1) Note: Median of Medians is also a selection algorithm we can use as an alternative for quickselect, but from the interviews perspective quickselect would be a good option","title":"4. Quick Select"},{"location":"ds_and_algo/sqrt_decomposition/","text":"TODO","title":"Square Root Decomposition"},{"location":"ds_and_algo/sqrt_decomposition/#todo","text":"","title":"TODO"},{"location":"ds_and_algo/trees/","text":"Variations of Trees Segment Tree Binary Index Tree - Fenwick Tree AVL Trees Red black trees Segment Tree Let's understand the segment trees and Binary index trees usage by a problem statement Problem: Given a array of integers, User would perform two operations 1. update an index in the array 2. request the sum of a range in the array Leetcode Problem: https://leetcode.com/problems/range-sum-query-mutable/ The brute force way of solving the above problem is class Nums: def __init__(self, nums): self.nums = nums def update_index(self, idx, value): self.nums[idx] = value def query_range(self, start_idx, end_idx): total = 0 for i in range(start_idx, end_idx + 1): total += self.nums[i] Time Complexity: - Update Index: O(1) - Query Range: O(n) Space Complexity: O(1) If there are many queries, i.e., n queries total time complexity for getting query range is n^2 Using the prefix sum we can fetch the query range values to O(1). Following is the implementation class Nums: def __init__(self, nums): self.nums = nums self.prefix = [] total = 0 for num in self.nums: total += num self.prefix.append(total) def update_index(self, idx, value): diff = value - self.nums[idx] self.nums[idx] = value for i in range(idx, len(self.nums)): self.nums[i] += diff def query_range(self, start_idx, end_idx): if start_idx == 0: return self.prefix[end_idx] return self.prefix[end_idx] - self.prefix[start_idx] Time Complexity: - Update Index: O(n) - Query Range: O(1) Space Complexity: O(n) The disadvantage of using the above solution is, if there are many updates (n update operations), then the time complexity would be n^2 For both large update operation and large range query operations, we can solve it via Segment trees and Binary Index Trees. Following is the implementation of Segment Tree class Nums: \"\"\" This implementation of segment tree is based on the recursion References: 1. https://leetcode.com/articles/a-recursive-approach-to-segment-trees-range-sum-queries-lazy-propagation/ 2. https://www.hackerearth.com/practice/data-structures/advanced-data-structures/segment-trees/tutorial/ 3. https://leetcode.com/problems/range-sum-query-mutable/discuss/1280869/Python%3A-All-possible-methods-Explained-with-time-and-space-complexity \"\"\" def __init__(self, nums): self.nums = nums self.nums_length = len(nums) self.tree = [0] * (4 * self.nums_length) # 0 to n -1 would be root nodes and n to 2 * n would be the input numbers which will be child nodes, for recursive solutions 4*n nodes are required self._build_tree(0, 0, self.nums_length - 1) self.lazy = [0] * (4 * self.nums_length) # this would be used for lazily updating the range queries def _build_tree(self, tree_idx, start, end): \"\"\" Consider the example nums array: [2,4,7,11] tree array initialization would be: [0, 0, 0, 0, 0, 0, 0, 0] following is the stack trace _build_tree(0, 0, 3) - [24, 6, 18, 2, 4, 7, 11, 0] step 7 _build_tree(1, 0, 1) - [0, 6, 0, 2, 4, 0, 0, 0] step 3 _build_tree(3, 0, 0) - [0, 0, 0, 2, 0, 0, 0, 0] step 1 _build_tree(4, 1, 1) - [0, 0, 0, 2, 4, 0, 0, 0] step 2 _build_tree(2, 2, 3) - [0, 6, 18, 2, 4, 7, 11, 0] step 6 _build_tree(5, 2, 2) - [0, 6, 0, 2, 4, 7, 0, 0] step 4 _build_tree(6, 3, 3) - [0, 6, 0, 2, 4, 7, 11, 0] step 5 \"\"\" if start == end: self.tree[tree_idx] = self.nums[start] return mid = start + (end - start) // 2 self._build_tree(2*tree_idx + 1, start, mid) self._build_tree(2*tree_idx + 2, mid + 1, end) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def _merge(self, val1, val2): \"\"\" This is for merging of two nodes, left and right child. In this case we are \"\"\" return val1 + val2 def update_index(self, tree_idx, start_idx, end_idx, arr_idx, value): # this place arry_idx will also be equal if start_idx == end_idx: self.tree[tree_idx] = value return mid = start_idx + (end_idx - start_idx) // 2 if arr_idx > mid: self.update_index(2*tree_idx + 2, mid + 1, end_idx, arr_idx, value) elif arr_idx <= mid: self.update_index(2*tree_idx + 1, start_idx, mid, arr_idx, value) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def query_range(self, tree_idx, start_idx, end_idx, query_start, query_end): # outside of the overlapping range if start_idx > query_end or end_idx < query_start: return 0 \"\"\" start and end are witin the query_start and query_end which means assuming start = 3, end = 5 and query_start = 1, query_end = 7 [3, 5] overlaps with [1, 7] we can directly return the value for [3, 5] and we can search for [1, 2] and [6, 7] \"\"\" if query_start <= start_idx and query_end >= end_idx: return self.tree[tree_idx] # if partial overlap mid = start_idx + (end_idx - start_idx) // 2 if query_start > mid: return self.query_range(2*tree_idx + 2, mid + 1, end_idx, query_start, query_end) elif query_end <= mid: return self.query_range(2*tree_idx + 1, start_idx, mid, query_start, query_end) \"\"\" if above both scenario's are not valid which means query_start and query_end values are near to start_idx and end_idx Example: start = 2, end = 7 and query_start=1, query_end=6 mid = start + (end - start) // 2 = 2 + (7-2) // 2 = 4 mid = 4 and it does not follow any of the if else conditions above, in this case we split into two group and process the two queries \"\"\" leftQuery = self.query_range(2*tree_idx + 1, start_idx, mid, query_start, mid) rightQuery = self.query_range(2*tree_idx + 2, mid + 1, end_idx, mid + 1, query_end) return self._merge(leftQuery, rightQuery) def _merge_lazy(self, start, end, tree_idx): \"\"\" Writing this method for the range sum queries and updates, but calculating the min and max in the range, it would be different reason for multiplying the (end - start + 1) is as we are summing those many nodes with the value, we are directly calculating the product and updating the value in the node, if both start and end are equal then value will be inserted otherwise for every other root node, we'll update by the number of child nodes \"\"\" return (end - start + 1) * self.lazy[tree_idx] def update_index_lazily(self, tree_idx, start, end, start_range, end_range, val): \"\"\" Lazy update will be helpful for the range of updates, rather than the single node update. Example: 1. Update [0, 4] with 9 2. Update [2, 3] with -8 3. Update [3, 4] with 2 In the above range updates, element 3 is being updated 3 times, rather than updating at the same time which would increase our time complexity to nlogn for single range update \"\"\" if self.lazy[tree_idx] != 0: # this means we have some pending updates self.tree[tree_idx] += self._merge_lazy(start, end, tree_idx) # udpating the value to the current node if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += self.lazy[tree_idx] self.lazy[2*tree_idx + 2] += self.lazy[tree_idx] # once the lazy value is udpated to the node and its children then we can reset the value back to zero self.lazy[tree_idx] = 0 if start > end or start_range > end or end_range < start: \"this will occur when there is no overlapping window\" return if start_range <= start and end >= end_range: # if the segment is fully within the range self.tree[tree_idx] += (end - start + 1) * val # updating the tree index value if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += val self.lazy[2*tree_idx + 2] += val return mid = start + (end-start) // 2 self.update_index_lazily(2*tree_idx + 1, start, mid, start_range, end_range, val) self.update_index_lazily(2*tree_idx + 2, mid + 1, end, start_range, end_range, val) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def query_lazily(self, tree_idx, start, end, query_start, query_end): # outside of the overlapping range if start_idx > query_end or end_idx < query_start: return 0 if self.lazy[tree_idx] != 0: # this means we have some pending updates self.tree[tree_idx] += self._merge_lazy(start, end, tree_idx) # udpating the value to the current node if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += self.lazy[tree_idx] self.lazy[2*tree_idx + 2] += self.lazy[tree_idx] # once the lazy value is udpated to the node and its children then we can reset the value back to zero self.lazy[tree_idx] = 0 \"\"\" start and end are witin the query_start and query_end which means assuming start = 3, end = 5 and query_start = 1, query_end = 7 [3, 5] overlaps with [1, 7] we can directly return the value for [3, 5] and we can search for [1, 2] and [6, 7] \"\"\" if query_start <= start_idx and query_end >= end_idx: return self.tree[tree_idx] # if partial overlap mid = start + (end - start) // 2 if query_start > mid: return self.query_lazily(2*tree_idx + 2, mid + 1, end_idx, query_start, query_end) elif query_end <= mid: return self.query_lazily(2*tree_idx + 1, start_idx, mid, query_start, query_end) \"\"\" if above both scenario's are not valid which means query_start and query_end values are near to start_idx and end_idx Example: start = 2, end = 7 and query_start=1, query_end=6 mid = start + (end - start) // 2 = 2 + (7-2) // 2 = 4 mid = 4 and it does not follow any of the if else conditions above, in this case we split into two group and process the two queries \"\"\" leftQuery = self.query_lazily(2*tree_idx + 1, start_idx, mid, query_start, mid) rightQuery = self.query_lazily(2*tree_idx + 2, mid + 1, end_idx, mid + 1, query_end) return self._merge(leftQuery, rightQuery) # this operation is dependent on the question, here we are doing sum The above program is a recursive way, we can write the same in non recursive way as well. Following is the code example class Nums: \"\"\" This is a non recursive way of implementing the segment tree, Much efficient way is described in this https://www.geeksforgeeks.org/segment-tree-efficient-implementation/ References: 1. Editorial section of https://leetcode.com/problems/range-sum-query-mutable/solution/ 2. https://github.com/jakobkogler/Algorithm-DataStructures/blob/master/RangeQuery/SegmentTree.py (https://leetcode.com/problems/range-sum-query-mutable/discuss/646774/Segment-tree-recursive-iterative-Binary-index-iterative-explained) \"\"\" def __init__(self, nums): self.nums = nums self.nums_length = len(nums) self.tree = [0] * (2 * self.nums_length) # 0 to n -1 would be root nodes and n to 2 * n would be the input numbers which will be child nodes self._build_tree() def _merge(self, val1, val2): \"\"\" Here we are trying to sum the values, for min segment tree, we need to find the min between the values \"\"\" return val1 + val2 def _build_tree(self): # child nodes start from the nums_length index for i in range(self.nums_length, 2*self.nums_length): self.tree[i] = self.nums[i-self.nums_length] # parent nodes, will occupy the starting positions, total number of nodes is (2*n - 1) for i in range(self.nums_length -1, -1, 0): self.tree[i] = self._merge(self.tree[2*i], self.tree[2*i + 1]) def update_idx(self, idx, value): \"\"\" Lets understand by taking an example nums = [2,4,7,11] tree = [0, 24, 6, 18, 2, 4, 7, 11] udpate idx = 3, val = 5 step 1 : [0, 24, 6, 18, 2, 4, 7, 5] # updating the value at idx + nums_length idx = 7 Go into the loop Step 2: left = 6, right = 7 tree[7//2] = tree[3] = tree[6] + tree[7] = 7 + 5 = 12 [0, 24, 6, 12, 2, 4, 7, 5] # updating the value at 3rd idx step 3: idx = 3 right = 3, left = 2 tree[1] = tree[3] + tree[2] = 18 [0, 18, 6, 12, 2, 4, 7, 5] # updating the value at 3rd idx In the next iteration idx is 1 so loop will stop \"\"\" idx += self.nums_length # map index to the second half to upate the node self.tree[idx] = value while idx > 1: left = idx right = idx if idx % 2 == 0: right = idx + 1 else: left = idx - 1 self.tree[idx // 2] = self.tree[left] + self.tree[right] idx //= 2 def query_range(self, start, end): \"\"\" let's understand with the example nums = [2,4,7,11] tree = [0, 24, 6, 18, 2, 4, 7, 11] Query range = [1, 3] // starting with zero index, so final answer should be 4+7+11=22 step1: start = 5, end = 8 step 2: total += tree[start] => total += 4 => total = 4, update start += 1 => start = 6 start = 3, end = 4 step 3: total += tree[start] => total += 18 => total = 22, start = 4 start = 2, end = 2 As the start not less than end, loop will get terminated \"\"\" start += self.nums_length end += (self.nums_length + 1) total = 0 while start < end: if start % 2 == 1: total += self.tree[start] start += 1 if end % 2 == 1: end -= 1 total += self.tree[end] start //= 2 end //= 2 return total Complete Working Code can be found from here Binary Index Tree - Fenwick Tree Binary Index Tree uses the binary representation of the indexes to store the values in the tree. Following the sample implementation. Binary Index Tree is also used for solving the range queries Reference: https://leetcode.com/problems/range-sum-query-mutable/discuss/75753/Java-using-Binary-Indexed-Tree-with-clear-explanation","title":"Trees"},{"location":"ds_and_algo/trees/#variations-of-trees","text":"Segment Tree Binary Index Tree - Fenwick Tree AVL Trees Red black trees","title":"Variations of Trees"},{"location":"ds_and_algo/trees/#segment-tree","text":"Let's understand the segment trees and Binary index trees usage by a problem statement Problem: Given a array of integers, User would perform two operations 1. update an index in the array 2. request the sum of a range in the array Leetcode Problem: https://leetcode.com/problems/range-sum-query-mutable/ The brute force way of solving the above problem is class Nums: def __init__(self, nums): self.nums = nums def update_index(self, idx, value): self.nums[idx] = value def query_range(self, start_idx, end_idx): total = 0 for i in range(start_idx, end_idx + 1): total += self.nums[i] Time Complexity: - Update Index: O(1) - Query Range: O(n) Space Complexity: O(1) If there are many queries, i.e., n queries total time complexity for getting query range is n^2 Using the prefix sum we can fetch the query range values to O(1). Following is the implementation class Nums: def __init__(self, nums): self.nums = nums self.prefix = [] total = 0 for num in self.nums: total += num self.prefix.append(total) def update_index(self, idx, value): diff = value - self.nums[idx] self.nums[idx] = value for i in range(idx, len(self.nums)): self.nums[i] += diff def query_range(self, start_idx, end_idx): if start_idx == 0: return self.prefix[end_idx] return self.prefix[end_idx] - self.prefix[start_idx] Time Complexity: - Update Index: O(n) - Query Range: O(1) Space Complexity: O(n) The disadvantage of using the above solution is, if there are many updates (n update operations), then the time complexity would be n^2 For both large update operation and large range query operations, we can solve it via Segment trees and Binary Index Trees. Following is the implementation of Segment Tree class Nums: \"\"\" This implementation of segment tree is based on the recursion References: 1. https://leetcode.com/articles/a-recursive-approach-to-segment-trees-range-sum-queries-lazy-propagation/ 2. https://www.hackerearth.com/practice/data-structures/advanced-data-structures/segment-trees/tutorial/ 3. https://leetcode.com/problems/range-sum-query-mutable/discuss/1280869/Python%3A-All-possible-methods-Explained-with-time-and-space-complexity \"\"\" def __init__(self, nums): self.nums = nums self.nums_length = len(nums) self.tree = [0] * (4 * self.nums_length) # 0 to n -1 would be root nodes and n to 2 * n would be the input numbers which will be child nodes, for recursive solutions 4*n nodes are required self._build_tree(0, 0, self.nums_length - 1) self.lazy = [0] * (4 * self.nums_length) # this would be used for lazily updating the range queries def _build_tree(self, tree_idx, start, end): \"\"\" Consider the example nums array: [2,4,7,11] tree array initialization would be: [0, 0, 0, 0, 0, 0, 0, 0] following is the stack trace _build_tree(0, 0, 3) - [24, 6, 18, 2, 4, 7, 11, 0] step 7 _build_tree(1, 0, 1) - [0, 6, 0, 2, 4, 0, 0, 0] step 3 _build_tree(3, 0, 0) - [0, 0, 0, 2, 0, 0, 0, 0] step 1 _build_tree(4, 1, 1) - [0, 0, 0, 2, 4, 0, 0, 0] step 2 _build_tree(2, 2, 3) - [0, 6, 18, 2, 4, 7, 11, 0] step 6 _build_tree(5, 2, 2) - [0, 6, 0, 2, 4, 7, 0, 0] step 4 _build_tree(6, 3, 3) - [0, 6, 0, 2, 4, 7, 11, 0] step 5 \"\"\" if start == end: self.tree[tree_idx] = self.nums[start] return mid = start + (end - start) // 2 self._build_tree(2*tree_idx + 1, start, mid) self._build_tree(2*tree_idx + 2, mid + 1, end) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def _merge(self, val1, val2): \"\"\" This is for merging of two nodes, left and right child. In this case we are \"\"\" return val1 + val2 def update_index(self, tree_idx, start_idx, end_idx, arr_idx, value): # this place arry_idx will also be equal if start_idx == end_idx: self.tree[tree_idx] = value return mid = start_idx + (end_idx - start_idx) // 2 if arr_idx > mid: self.update_index(2*tree_idx + 2, mid + 1, end_idx, arr_idx, value) elif arr_idx <= mid: self.update_index(2*tree_idx + 1, start_idx, mid, arr_idx, value) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def query_range(self, tree_idx, start_idx, end_idx, query_start, query_end): # outside of the overlapping range if start_idx > query_end or end_idx < query_start: return 0 \"\"\" start and end are witin the query_start and query_end which means assuming start = 3, end = 5 and query_start = 1, query_end = 7 [3, 5] overlaps with [1, 7] we can directly return the value for [3, 5] and we can search for [1, 2] and [6, 7] \"\"\" if query_start <= start_idx and query_end >= end_idx: return self.tree[tree_idx] # if partial overlap mid = start_idx + (end_idx - start_idx) // 2 if query_start > mid: return self.query_range(2*tree_idx + 2, mid + 1, end_idx, query_start, query_end) elif query_end <= mid: return self.query_range(2*tree_idx + 1, start_idx, mid, query_start, query_end) \"\"\" if above both scenario's are not valid which means query_start and query_end values are near to start_idx and end_idx Example: start = 2, end = 7 and query_start=1, query_end=6 mid = start + (end - start) // 2 = 2 + (7-2) // 2 = 4 mid = 4 and it does not follow any of the if else conditions above, in this case we split into two group and process the two queries \"\"\" leftQuery = self.query_range(2*tree_idx + 1, start_idx, mid, query_start, mid) rightQuery = self.query_range(2*tree_idx + 2, mid + 1, end_idx, mid + 1, query_end) return self._merge(leftQuery, rightQuery) def _merge_lazy(self, start, end, tree_idx): \"\"\" Writing this method for the range sum queries and updates, but calculating the min and max in the range, it would be different reason for multiplying the (end - start + 1) is as we are summing those many nodes with the value, we are directly calculating the product and updating the value in the node, if both start and end are equal then value will be inserted otherwise for every other root node, we'll update by the number of child nodes \"\"\" return (end - start + 1) * self.lazy[tree_idx] def update_index_lazily(self, tree_idx, start, end, start_range, end_range, val): \"\"\" Lazy update will be helpful for the range of updates, rather than the single node update. Example: 1. Update [0, 4] with 9 2. Update [2, 3] with -8 3. Update [3, 4] with 2 In the above range updates, element 3 is being updated 3 times, rather than updating at the same time which would increase our time complexity to nlogn for single range update \"\"\" if self.lazy[tree_idx] != 0: # this means we have some pending updates self.tree[tree_idx] += self._merge_lazy(start, end, tree_idx) # udpating the value to the current node if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += self.lazy[tree_idx] self.lazy[2*tree_idx + 2] += self.lazy[tree_idx] # once the lazy value is udpated to the node and its children then we can reset the value back to zero self.lazy[tree_idx] = 0 if start > end or start_range > end or end_range < start: \"this will occur when there is no overlapping window\" return if start_range <= start and end >= end_range: # if the segment is fully within the range self.tree[tree_idx] += (end - start + 1) * val # updating the tree index value if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += val self.lazy[2*tree_idx + 2] += val return mid = start + (end-start) // 2 self.update_index_lazily(2*tree_idx + 1, start, mid, start_range, end_range, val) self.update_index_lazily(2*tree_idx + 2, mid + 1, end, start_range, end_range, val) self.tree[tree_idx] = self._merge(self.tree[2*tree_idx + 1], self.tree[2*tree_idx + 2]) def query_lazily(self, tree_idx, start, end, query_start, query_end): # outside of the overlapping range if start_idx > query_end or end_idx < query_start: return 0 if self.lazy[tree_idx] != 0: # this means we have some pending updates self.tree[tree_idx] += self._merge_lazy(start, end, tree_idx) # udpating the value to the current node if start != end: # if we are not updating to the child node, then pass the lazy value to the child nodes self.lazy[2*tree_idx + 1] += self.lazy[tree_idx] self.lazy[2*tree_idx + 2] += self.lazy[tree_idx] # once the lazy value is udpated to the node and its children then we can reset the value back to zero self.lazy[tree_idx] = 0 \"\"\" start and end are witin the query_start and query_end which means assuming start = 3, end = 5 and query_start = 1, query_end = 7 [3, 5] overlaps with [1, 7] we can directly return the value for [3, 5] and we can search for [1, 2] and [6, 7] \"\"\" if query_start <= start_idx and query_end >= end_idx: return self.tree[tree_idx] # if partial overlap mid = start + (end - start) // 2 if query_start > mid: return self.query_lazily(2*tree_idx + 2, mid + 1, end_idx, query_start, query_end) elif query_end <= mid: return self.query_lazily(2*tree_idx + 1, start_idx, mid, query_start, query_end) \"\"\" if above both scenario's are not valid which means query_start and query_end values are near to start_idx and end_idx Example: start = 2, end = 7 and query_start=1, query_end=6 mid = start + (end - start) // 2 = 2 + (7-2) // 2 = 4 mid = 4 and it does not follow any of the if else conditions above, in this case we split into two group and process the two queries \"\"\" leftQuery = self.query_lazily(2*tree_idx + 1, start_idx, mid, query_start, mid) rightQuery = self.query_lazily(2*tree_idx + 2, mid + 1, end_idx, mid + 1, query_end) return self._merge(leftQuery, rightQuery) # this operation is dependent on the question, here we are doing sum The above program is a recursive way, we can write the same in non recursive way as well. Following is the code example class Nums: \"\"\" This is a non recursive way of implementing the segment tree, Much efficient way is described in this https://www.geeksforgeeks.org/segment-tree-efficient-implementation/ References: 1. Editorial section of https://leetcode.com/problems/range-sum-query-mutable/solution/ 2. https://github.com/jakobkogler/Algorithm-DataStructures/blob/master/RangeQuery/SegmentTree.py (https://leetcode.com/problems/range-sum-query-mutable/discuss/646774/Segment-tree-recursive-iterative-Binary-index-iterative-explained) \"\"\" def __init__(self, nums): self.nums = nums self.nums_length = len(nums) self.tree = [0] * (2 * self.nums_length) # 0 to n -1 would be root nodes and n to 2 * n would be the input numbers which will be child nodes self._build_tree() def _merge(self, val1, val2): \"\"\" Here we are trying to sum the values, for min segment tree, we need to find the min between the values \"\"\" return val1 + val2 def _build_tree(self): # child nodes start from the nums_length index for i in range(self.nums_length, 2*self.nums_length): self.tree[i] = self.nums[i-self.nums_length] # parent nodes, will occupy the starting positions, total number of nodes is (2*n - 1) for i in range(self.nums_length -1, -1, 0): self.tree[i] = self._merge(self.tree[2*i], self.tree[2*i + 1]) def update_idx(self, idx, value): \"\"\" Lets understand by taking an example nums = [2,4,7,11] tree = [0, 24, 6, 18, 2, 4, 7, 11] udpate idx = 3, val = 5 step 1 : [0, 24, 6, 18, 2, 4, 7, 5] # updating the value at idx + nums_length idx = 7 Go into the loop Step 2: left = 6, right = 7 tree[7//2] = tree[3] = tree[6] + tree[7] = 7 + 5 = 12 [0, 24, 6, 12, 2, 4, 7, 5] # updating the value at 3rd idx step 3: idx = 3 right = 3, left = 2 tree[1] = tree[3] + tree[2] = 18 [0, 18, 6, 12, 2, 4, 7, 5] # updating the value at 3rd idx In the next iteration idx is 1 so loop will stop \"\"\" idx += self.nums_length # map index to the second half to upate the node self.tree[idx] = value while idx > 1: left = idx right = idx if idx % 2 == 0: right = idx + 1 else: left = idx - 1 self.tree[idx // 2] = self.tree[left] + self.tree[right] idx //= 2 def query_range(self, start, end): \"\"\" let's understand with the example nums = [2,4,7,11] tree = [0, 24, 6, 18, 2, 4, 7, 11] Query range = [1, 3] // starting with zero index, so final answer should be 4+7+11=22 step1: start = 5, end = 8 step 2: total += tree[start] => total += 4 => total = 4, update start += 1 => start = 6 start = 3, end = 4 step 3: total += tree[start] => total += 18 => total = 22, start = 4 start = 2, end = 2 As the start not less than end, loop will get terminated \"\"\" start += self.nums_length end += (self.nums_length + 1) total = 0 while start < end: if start % 2 == 1: total += self.tree[start] start += 1 if end % 2 == 1: end -= 1 total += self.tree[end] start //= 2 end //= 2 return total Complete Working Code can be found from here","title":"Segment Tree"},{"location":"ds_and_algo/trees/#binary-index-tree-fenwick-tree","text":"Binary Index Tree uses the binary representation of the indexes to store the values in the tree. Following the sample implementation. Binary Index Tree is also used for solving the range queries Reference: https://leetcode.com/problems/range-sum-query-mutable/discuss/75753/Java-using-Binary-Indexed-Tree-with-clear-explanation","title":"Binary Index Tree - Fenwick Tree"},{"location":"ds_and_algo/two_pointers/","text":"","title":"Two Pointers"},{"location":"system_design/useful_links/","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Useful Links"},{"location":"system_design/useful_links/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"system_design/useful_links/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"system_design/useful_links/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"}]}